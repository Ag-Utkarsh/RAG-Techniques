{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This code implements a Fusion Retrieval system that combines vector-based similarity search with keyword-based BM25 retrieval. The approach aims to leverage the strengths of both methods to improve the overall quality and relevance of document retrieval.\n",
        "\n",
        "Traditional retrieval methods often rely on either semantic understanding (vector-based) or keyword matching (BM25). Each approach has its strengths and weaknesses. Fusion retrieval aims to combine these methods to create a more robust and accurate retrieval system that can handle a wider range of queries effectively."
      ],
      "metadata": {
        "id": "kRSdjzo60lmg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Package Installatin and Imports"
      ],
      "metadata": {
        "id": "tXe-AZFV0_NU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1uDxwszz1Mn",
        "outputId": "73454d9e-3671-43f7-ade3-766e958b8cdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.12/dist-packages (0.3.33)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.29)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.12/dist-packages (0.2.2)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.1.0)\n",
            "Requirement already satisfied: tools in /usr/local/lib/python3.12/dist-packages (1.0.5)\n",
            "Requirement already satisfied: deepeval in /usr/local/lib/python3.12/dist-packages (3.5.4)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.76 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.3.76)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.107.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.27)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.12/dist-packages (from deepeval) (0.68.0)\n",
            "Requirement already satisfied: click<8.3.0,>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (8.2.1)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.34.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.67.1 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.74.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.6.0)\n",
            "Requirement already satisfied: ollama in /usr/local/lib/python3.12/dist-packages (from deepeval) (0.5.4)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.37.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from deepeval) (3.2.0)\n",
            "Requirement already satisfied: posthog<7.0.0,>=6.3.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (6.7.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.11.7 in /usr/local/lib/python3.12/dist-packages (from deepeval) (2.11.7)\n",
            "Requirement already satisfied: pyfiglet in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.0.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from deepeval) (8.4.2)\n",
            "Requirement already satisfied: pytest-asyncio in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.2.0)\n",
            "Requirement already satisfied: pytest-repeat in /usr/local/lib/python3.12/dist-packages (from deepeval) (0.9.4)\n",
            "Requirement already satisfied: pytest-rerunfailures<13.0,>=12.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (12.0)\n",
            "Requirement already satisfied: pytest-xdist in /usr/local/lib/python3.12/dist-packages (from deepeval) (3.8.0)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.1.1)\n",
            "Requirement already satisfied: rich<15.0.0,>=13.6.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (13.9.4)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.12/dist-packages (from deepeval) (2.37.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from deepeval) (75.2.0)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from deepeval) (4.67.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.9 in /usr/local/lib/python3.12/dist-packages (from deepeval) (0.17.4)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (from deepeval) (0.45.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.9.0->deepeval) (4.10.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.9.0->deepeval) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.9.0->deepeval) (0.28.1)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.9.0->deepeval) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.9.0->deepeval) (4.15.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (1.33)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.24.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.24.0->deepeval) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.37.0)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (5.29.5)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval) (0.58b0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from posthog<7.0.0,>=6.3.0->deepeval) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.12/dist-packages (from posthog<7.0.0,>=6.3.0->deepeval) (2.9.0.post0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<7.0.0,>=6.3.0->deepeval) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.11.7->deepeval) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.11.7->deepeval) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.11.7->deepeval) (0.4.1)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->deepeval) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->deepeval) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest->deepeval) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=13.6.0->deepeval) (4.0.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.9->deepeval) (1.5.4)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic->deepeval) (0.17.0)\n",
            "Requirement already satisfied: execnet>=2.1 in /usr/local/lib/python3.12/dist-packages (from pytest-xdist->deepeval) (2.1.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.9.0->deepeval) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.9.0->deepeval) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.24.0->deepeval) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.76->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.6.0->deepeval) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_openai langchain-community numpy rank-bm25 pypdf tools deepeval faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NirDiamant/RAG_TECHNIQUES.git\n",
        "import sys\n",
        "sys.path.append('RAG_TECHNIQUES')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHBct_v-3Fch",
        "outputId": "80e70e76-fb16-4899-e615-b09e9292a287"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'RAG_TECHNIQUES' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from langchain.docstore.document import Document\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "from typing import List\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "\n",
        "from helper_functions import *\n",
        "from evaluation.evalute_rag import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKZidGIt3IT-",
        "outputId": "4043c60b-14e7-4076-9ff3-0e27db7e869d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2280760897.py:12: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  from helper_functions import *\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required data files\n",
        "import os\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "# Download the PDF document used in this notebook\n",
        "!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0KCdZkM6INc",
        "outputId": "e7143dc8-0e6c-4a7f-e44c-019268cec582"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-22 14:58:28--  https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206372 (202K) [application/octet-stream]\n",
            "Saving to: ‘data/Understanding_Climate_Change.pdf’\n",
            "\n",
            "\r          data/Unde   0%[                    ]       0  --.-KB/s               \rdata/Understanding_ 100%[===================>] 201.54K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-09-22 14:58:29 (8.28 MB/s) - ‘data/Understanding_Climate_Change.pdf’ saved [206372/206372]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"data/Understanding_Climate_Change.pdf\""
      ],
      "metadata": {
        "id": "M9NR_BH56Nms"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Encode the pdf to vector store and return split document from the step before to create BM25 instance"
      ],
      "metadata": {
        "id": "sSCcET8X6TRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_pdf_and_get_split_documents(path, chunk_size=1000, chunk_overlap=200):\n",
        "    \"\"\"\n",
        "    Encodes a PDF book into a vector store using OpenAI embeddings.\n",
        "\n",
        "    Args:\n",
        "        path: The path to the PDF file.\n",
        "        chunk_size: The desired size of each text chunk.\n",
        "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
        "\n",
        "    Returns:\n",
        "        A FAISS vector store containing the encoded book content.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load PDF documents\n",
        "    loader = PyPDFLoader(path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    # Split documents into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
        "    )\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    cleaned_texts = replace_t_with_space(texts)\n",
        "\n",
        "    # Create embeddings and vector store\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
        "\n",
        "    return vectorstore, cleaned_texts"
      ],
      "metadata": {
        "id": "aLwRjE2Q6fOh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Create vectorstore and get the chunked documents"
      ],
      "metadata": {
        "id": "bACi66F46pay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore, cleaned_texts = encode_pdf_and_get_split_documents(path)"
      ],
      "metadata": {
        "id": "uosZjcVJ6uaC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Create a bm25 index for retrieving documents by keywords"
      ],
      "metadata": {
        "id": "QHFs95zl7yKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bm25_index(documents: List[Document]) -> BM25Okapi:\n",
        "    \"\"\"\n",
        "    Create a BM25 index from the given documents.\n",
        "\n",
        "    BM25 (Best Matching 25) is a ranking function used in information retrieval.\n",
        "    It's based on the probabilistic retrieval framework and is an improvement over TF-IDF.\n",
        "\n",
        "    Args:\n",
        "    documents (List[Document]): List of documents to index.\n",
        "\n",
        "    Returns:\n",
        "    BM25Okapi: An index that can be used for BM25 scoring.\n",
        "    \"\"\"\n",
        "    # Tokenize each document by splitting on whitespace\n",
        "    # This is a simple approach and could be improved with more sophisticated tokenization\n",
        "    tokenized_docs = [doc.page_content.split() for doc in documents]\n",
        "    return BM25Okapi(tokenized_docs)"
      ],
      "metadata": {
        "id": "QSSNwEmW76GO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm25 = create_bm25_index(cleaned_texts) # Create BM25 index from the cleaned texts (chunks)"
      ],
      "metadata": {
        "id": "EBUHWs7Q8FKr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Define a function that retrieves both semantically and by keyword, normalizes the scores and gets the top k documents"
      ],
      "metadata": {
        "id": "d3ODBgkv8QSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fusion_retrieval(vectorstore, bm25, query: str, k: int = 5, alpha: float = 0.5) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Perform fusion retrieval combining keyword-based (BM25) and vector-based search.\n",
        "\n",
        "    Args:\n",
        "    vectorstore (VectorStore): The vectorstore containing the documents.\n",
        "    bm25 (BM25Okapi): Pre-computed BM25 index.\n",
        "    query (str): The query string.\n",
        "    k (int): The number of documents to retrieve.\n",
        "    alpha (float): The weight for vector search scores (1-alpha will be the weight for BM25 scores).\n",
        "\n",
        "    Returns:\n",
        "    List[Document]: The top k documents based on the combined scores.\n",
        "    \"\"\"\n",
        "\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    # Step 1: Get all documents from the vectorstore\n",
        "    all_docs = vectorstore.similarity_search(\"\", k=vectorstore.index.ntotal)\n",
        "\n",
        "    # Step 2: Perform BM25 search\n",
        "    bm25_scores = bm25.get_scores(query.split())\n",
        "\n",
        "    # Step 3: Perform vector search\n",
        "    vector_results = vectorstore.similarity_search_with_score(query, k=len(all_docs))\n",
        "\n",
        "    # Step 4: Normalize scores\n",
        "    vector_scores = np.array([score for _, score in vector_results])\n",
        "    vector_scores = 1 - (vector_scores - np.min(vector_scores)) / (np.max(vector_scores) - np.min(vector_scores) + epsilon)\n",
        "\n",
        "    bm25_scores = (bm25_scores - np.min(bm25_scores)) / (np.max(bm25_scores) -  np.min(bm25_scores) + epsilon)\n",
        "\n",
        "    # Step 5: Combine scores\n",
        "    combined_scores = alpha * vector_scores + (1 - alpha) * bm25_scores\n",
        "\n",
        "    # Step 6: Rank documents\n",
        "    sorted_indices = np.argsort(combined_scores)[::-1]\n",
        "\n",
        "    # Step 7: Return top k documents\n",
        "    return [all_docs[i] for i in sorted_indices[:k]]"
      ],
      "metadata": {
        "id": "8cpu7-dP8aly"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Example"
      ],
      "metadata": {
        "id": "2IoGWUaL8pLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Query\n",
        "query = \"What are the impacts of climate change on the environment?\"\n",
        "\n",
        "# Perform fusion retrieval\n",
        "top_docs = fusion_retrieval(vectorstore, bm25, query, k=5, alpha=0.5)\n",
        "docs_content = [doc.page_content for doc in top_docs]\n",
        "show_context(docs_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDArePWu8qf1",
        "outputId": "cfb150e0-7b77-4a7a-aa16-38121fc15482"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context 1:\n",
            "Legacy and Responsibility \n",
            "Recognizing the responsibility to future generations is a fundamental aspect of climate action. \n",
            "This involves making decisions that protect the environment and ensure a sustainable future. \n",
            "Promoting a sense of stewardship and legacy encourages long-term thinking and \n",
            "commitment. \n",
            "By continuing to innovate, collaborate, and integrate diverse perspectives, we can address the \n",
            "complex and urgent challenge of climate change. Our collective efforts will determine the \n",
            "health and sustainability of our planet for generations to come. Together, we can create a \n",
            "resilient, equitable, and thriving world.\n",
            "\n",
            "\n",
            "Context 2:\n",
            "arid and semi-arid regions. Droughts can lead to food and water shortages and exacerbate \n",
            "conflicts. \n",
            "Flooding \n",
            "Heavy rainfall events are becoming more common, leading to increased flooding. Urban \n",
            "areas with poor drainage and infrastructure are particularly at risk. Flood management \n",
            "strategies include improved drainage systems, green infrastructure, and floodplain restoration. \n",
            "Ocean Acidification \n",
            "Increased CO2 levels in the atmosphere lead to higher concentrations of CO2 in the oceans. \n",
            "This causes the water to become more acidic, which can harm marine life, particularly \n",
            "organisms with calcium carbonate shells or skeletons, such as corals and some shellfish. \n",
            "Coral Reefs\n",
            "\n",
            "\n",
            "Context 3:\n",
            "Vision for a Sustainable Future \n",
            "Holistic Approach \n",
            "Addressing climate change requires a holistic approach that integrates environmental, social, \n",
            "and economic dimensions. Sustainable development, circular economy, and ecological justice \n",
            "are key principles guiding this approach. Collaboration across sectors and scales is essential \n",
            "for achieving a sustainable future. \n",
            "Innovation and Creativity \n",
            "Innovation and creativity are vital for developing new solutions to climate challenges. This \n",
            "includes technological advancements, policy innovations, and creative approaches to \n",
            "education and communication. Fostering a culture of innovation supports continuous \n",
            "improvement and adaptation. \n",
            "Global Solidarity \n",
            "Global solidarity and cooperation are fundamental for addressing the global challenge of \n",
            "climate change. This includes supporting vulnerable countries and communities, sharing \n",
            "resources and technologies, and promoting equitable solutions. Solidarity strengthens global\n",
            "\n",
            "\n",
            "Context 4:\n",
            "goals. Policies should promote synergies between biodiversity conservation and climate \n",
            "action. \n",
            "Chapter 10: Climate Change and Human Health \n",
            "Health Impacts \n",
            "Heat-Related Illnesses \n",
            "Rising temperatures and more frequent heatwaves increase the risk of heat-related illnesses, \n",
            "such as heat exhaustion and heatstroke. Vulnerable populations, including the elderly, \n",
            "children, and outdoor workers, are particularly at risk. Heat mitigation strategies, such as \n",
            "cooling centers and public health campaigns, are essential. \n",
            "Vector-Borne Diseases \n",
            "Climate change affects the distribution and prevalence of vector-borne diseases, such as \n",
            "malaria, dengue fever, and Lyme disease. Warmer temperatures and changing precipitation \n",
            "patterns can expand the habitats of disease-carrying insects, increasing the risk of outbreaks. \n",
            "Integrated pest management and disease surveillance are critical for prevention and control. \n",
            "Respiratory and Cardiovascular Diseases\n",
            "\n",
            "\n",
            "Context 5:\n",
            "This vision includes a healthy planet, thriving ecosystems, and equitable societies. Working \n",
            "together towards this vision creates a sense of purpose and motivation. \n",
            "By embracing these principles and taking concerted action, we can address the urgent \n",
            "challenge of climate change and build a sustainable, resilient, and equitable world for all. The \n",
            "path forward requires courage, commitment, and collaboration, but the rewards are \n",
            "immense—a thriving planet and a prosperous future for generations to come. \n",
            "Chapter 13: Climate Change and Social Justice \n",
            "Climate Justice \n",
            "Understanding Climate Justice \n",
            "Climate justice emphasizes the ethical dimensions of climate change, recognizing that its \n",
            "impacts are not evenly distributed. Vulnerable populations, including low-income \n",
            "communities, indigenous peoples, and marginalized groups, often face the greatest risks \n",
            "while contributing the least to greenhouse gas emissions. Climate justice advocates for\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}